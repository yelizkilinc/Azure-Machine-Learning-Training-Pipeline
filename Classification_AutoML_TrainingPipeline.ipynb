{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import json\r\n",
        "import logging\r\n",
        "\r\n",
        "from matplotlib import pyplot as plt\r\n",
        "import pandas as pd\r\n",
        "import os\r\n",
        "\r\n",
        "import azureml.core\r\n",
        "from azureml.core.experiment import Experiment\r\n",
        "from azureml.core.workspace import Workspace\r\n",
        "from azureml.core.dataset import Dataset\r\n",
        "from azureml.train.automl import AutoMLConfig\r\n",
        "from azureml.interpret import ExplanationClient # kismi sonradan ekle"
      ],
      "outputs": [],
      "execution_count": 66,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ws = Workspace.from_config()"
      ],
      "outputs": [],
      "execution_count": 59,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\r\n",
        "from azureml.core.compute_target import ComputeTargetException\r\n",
        "\r\n",
        "pipeline_cluster = \"yk-compute-cluster\"\r\n",
        "compute_target = ws.compute_targets[pipeline_cluster]"
      ],
      "outputs": [],
      "execution_count": 67,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\r\n",
        "    \"https://automlsamplenotebookdata.blob.core.windows.net/automl-sample-notebook-data/bankmarketing_train.csv\"\r\n",
        ")\r\n",
        "data.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 41,
          "data": {
            "text/plain": "   age          job  marital    education  default housing loan    contact  \\\n0   57   technician  married  high.school       no      no  yes   cellular   \n1   55      unknown  married      unknown  unknown     yes   no  telephone   \n2   33  blue-collar  married     basic.9y       no      no   no   cellular   \n3   36       admin.  married  high.school       no      no   no  telephone   \n4   27    housemaid  married  high.school       no     yes   no   cellular   \n\n  month day_of_week  ...  campaign  pdays  previous     poutcome emp.var.rate  \\\n0   may         mon  ...         1    999         1      failure         -1.8   \n1   may         thu  ...         2    999         0  nonexistent          1.1   \n2   may         fri  ...         1    999         1      failure         -1.8   \n3   jun         fri  ...         4    999         0  nonexistent          1.4   \n4   jul         fri  ...         2    999         0  nonexistent          1.4   \n\n   cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n0          92.893          -46.2      1.299       5099.1  no  \n1          93.994          -36.4      4.860       5191.0  no  \n2          92.893          -46.2      1.313       5099.1  no  \n3          94.465          -41.8      4.967       5228.1  no  \n4          93.918          -42.7      4.963       5228.1  no  \n\n[5 rows x 21 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>job</th>\n      <th>marital</th>\n      <th>education</th>\n      <th>default</th>\n      <th>housing</th>\n      <th>loan</th>\n      <th>contact</th>\n      <th>month</th>\n      <th>day_of_week</th>\n      <th>...</th>\n      <th>campaign</th>\n      <th>pdays</th>\n      <th>previous</th>\n      <th>poutcome</th>\n      <th>emp.var.rate</th>\n      <th>cons.price.idx</th>\n      <th>cons.conf.idx</th>\n      <th>euribor3m</th>\n      <th>nr.employed</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>57</td>\n      <td>technician</td>\n      <td>married</td>\n      <td>high.school</td>\n      <td>no</td>\n      <td>no</td>\n      <td>yes</td>\n      <td>cellular</td>\n      <td>may</td>\n      <td>mon</td>\n      <td>...</td>\n      <td>1</td>\n      <td>999</td>\n      <td>1</td>\n      <td>failure</td>\n      <td>-1.8</td>\n      <td>92.893</td>\n      <td>-46.2</td>\n      <td>1.299</td>\n      <td>5099.1</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>55</td>\n      <td>unknown</td>\n      <td>married</td>\n      <td>unknown</td>\n      <td>unknown</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>telephone</td>\n      <td>may</td>\n      <td>thu</td>\n      <td>...</td>\n      <td>2</td>\n      <td>999</td>\n      <td>0</td>\n      <td>nonexistent</td>\n      <td>1.1</td>\n      <td>93.994</td>\n      <td>-36.4</td>\n      <td>4.860</td>\n      <td>5191.0</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>33</td>\n      <td>blue-collar</td>\n      <td>married</td>\n      <td>basic.9y</td>\n      <td>no</td>\n      <td>no</td>\n      <td>no</td>\n      <td>cellular</td>\n      <td>may</td>\n      <td>fri</td>\n      <td>...</td>\n      <td>1</td>\n      <td>999</td>\n      <td>1</td>\n      <td>failure</td>\n      <td>-1.8</td>\n      <td>92.893</td>\n      <td>-46.2</td>\n      <td>1.313</td>\n      <td>5099.1</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>36</td>\n      <td>admin.</td>\n      <td>married</td>\n      <td>high.school</td>\n      <td>no</td>\n      <td>no</td>\n      <td>no</td>\n      <td>telephone</td>\n      <td>jun</td>\n      <td>fri</td>\n      <td>...</td>\n      <td>4</td>\n      <td>999</td>\n      <td>0</td>\n      <td>nonexistent</td>\n      <td>1.4</td>\n      <td>94.465</td>\n      <td>-41.8</td>\n      <td>4.967</td>\n      <td>5228.1</td>\n      <td>no</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>27</td>\n      <td>housemaid</td>\n      <td>married</td>\n      <td>high.school</td>\n      <td>no</td>\n      <td>yes</td>\n      <td>no</td>\n      <td>cellular</td>\n      <td>jul</td>\n      <td>fri</td>\n      <td>...</td>\n      <td>2</td>\n      <td>999</td>\n      <td>0</td>\n      <td>nonexistent</td>\n      <td>1.4</td>\n      <td>93.918</td>\n      <td>-42.7</td>\n      <td>4.963</td>\n      <td>5228.1</td>\n      <td>no</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 21 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 41,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.data.dataset_factory import TabularDatasetFactory\r\n",
        "\r\n",
        "datastore = ws.get_default_datastore()#we will store intermediate data between data preparation and automated ml step in the workspace default datastore.\r\n",
        "train_data = TabularDatasetFactory.register_pandas_dataframe(\r\n",
        "    data, target=(datastore, \"dataset/\"), name=\"AutoMLE2EPipeline_Classification_train\"\r\n",
        ")\r\n",
        "#I creat dataset from pandas dataframe\r\n",
        "#Other way: You can create  dataset by using ds=Dataset.Tabular.from_delimited_files(path=xxx) and register it with ds.register()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Validating arguments.\nArguments validated.\nSuccessfully obtained datastore reference and path.\nUploading file to dataset//64608141-42eb-43d6-bc8c-1389844f9d68/\nColumn header contains '.' This period will be translated to '_' as we write the data out to parquet files: 'emp.var.rate' -> 'emp_var_rate'\nColumn header contains '.' This period will be translated to '_' as we write the data out to parquet files: 'cons.price.idx' -> 'cons_price_idx'\nColumn header contains '.' This period will be translated to '_' as we write the data out to parquet files: 'cons.conf.idx' -> 'cons_conf_idx'\nColumn header contains '.' This period will be translated to '_' as we write the data out to parquet files: 'nr.employed' -> 'nr_employed'\nSuccessfully uploaded file to datastore.\nCreating and registering a new dataset.\nSuccessfully created and registered a new dataset.\n"
        }
      ],
      "execution_count": 68,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Target: Configure the training run\r\n",
        "from azureml.core import Environment\r\n",
        "from azureml.core.runconfig import RunConfiguration\r\n",
        "from azureml.core.conda_dependencies import CondaDependencies\r\n",
        "\r\n",
        "#env = Environment.get(workspace=ws, name='experiment_env', version='2')\r\n",
        "\r\n",
        "pipeline_run_config=RunConfiguration()\r\n",
        "pipeline_run_config.target= compute_target\r\n",
        "\r\n",
        "# Add conda dependencies to the automl env:\r\n",
        "pipeline_run_config.environment.python.conda_dependencies = CondaDependencies.create(\r\n",
        " conda_packages=['pandas'])  "
      ],
      "outputs": [],
      "execution_count": 119,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.data import OutputFileDatasetConfig\r\n",
        "from azureml.pipeline.steps import PythonScriptStep\r\n",
        "import datetime\r\n",
        "\r\n",
        "#1st way: OutputFileDatasetConfig without giving destination\r\n",
        "#prepped_output_path = OutputFileDatasetConfig(name=\"output_path\") \r\n",
        "\r\n",
        "#2nd way: OutputFileDatasetConfig with giving destination\r\n",
        "output_path = (datastore, f\"azureml/classification_prep_output/\")\r\n",
        "prepped_output_path = OutputFileDatasetConfig(destination = output_path)\r\n",
        "# OutputFileDatasetConfig  points a directory and CSV file will be written there. Also given as parameter below.\r\n",
        "# If you do not give destination parameter, it will copy the output to the workspaceblobstore datastore, under the path /dataset/{run-id}/{output-name}. \r\n",
        "# Run-id is the name value on the overview of the job and outputname is the name given as a parameter. In my example, it is output_path.\r\n",
        "\r\n",
        "input_ds = Dataset.get_by_name(ws, 'AutoMLE2EPipeline_Classification_train')\r\n",
        "\r\n",
        "prep_step=PythonScriptStep(\r\n",
        "    name=\"Prepare AutoML Classification\",\r\n",
        "    script_name=\"prepare.py\",\r\n",
        "    source_directory=\"./Scripts\",\r\n",
        "    #arguments=['--input-data',input_ds.as_named_input('AutoMLE2EPipeline_Classification_train'),'--prepped-data',output],\r\n",
        "    arguments=[\"--output_path\",prepped_output_path],\r\n",
        "    inputs=[input_ds.as_named_input('AutoMLE2EPipeline_Classification_train')],\r\n",
        "    compute_target=compute_target,\r\n",
        "    runconfig=pipeline_run_config\r\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 120,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#In an ML pipeline, the input data must be a Dataset object.\r\n",
        "\r\n",
        "prepped_data=prepped_output_path.read_delimited_files() # This is the data to send automlstep\r\n",
        "\r\n",
        "from azureml.pipeline.core import TrainingOutput,PipelineData\r\n",
        "\r\n",
        "metrics_data = PipelineData(name='metrics_data',\r\n",
        "                            datastore=datastore,\r\n",
        "                            pipeline_output_name='metrics_output',\r\n",
        "                            training_output=TrainingOutput(type='Metrics'))\r\n",
        "\r\n",
        "model_data = PipelineData(name='best_model_data',\r\n",
        "                          datastore=datastore,\r\n",
        "                          pipeline_output_name='model_output',\r\n",
        "                          training_output=TrainingOutput(type='Model'))\r\n",
        "# two pipelinedata objects for automl outputs: metrics and the model.\r\n"
      ],
      "outputs": [],
      "execution_count": 121,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.train.automl import AutoMLConfig\r\n",
        "from azureml.pipeline.steps import AutoMLStep\r\n",
        "\r\n",
        "# Change iterations to a reasonable number (50) to get better accuracy\r\n",
        "automl_settings = {\r\n",
        "    \"iteration_timeout_minutes\" : 10,\r\n",
        "    \"iterations\" : 2,\r\n",
        "    \"experiment_timeout_hours\" : 0.25,\r\n",
        "    \"primary_metric\" : 'AUC_weighted'\r\n",
        "}\r\n",
        "#the run will stop after only 2 iterations or 15 minutes, whichever comes first.\r\n",
        "\r\n",
        "automl_config = AutoMLConfig(task = 'classification',\r\n",
        "                             path = '.',\r\n",
        "                             debug_log = 'automated_ml_errors.log',\r\n",
        "                             compute_target= compute_target,\r\n",
        "                             run_configuration = pipeline_run_config,\r\n",
        "                             featurization = 'auto',\r\n",
        "                             training_data = prepped_data,\r\n",
        "                             label_column_name = 'y',\r\n",
        "                             **automl_settings)\r\n",
        "# debug_log local file if you want to see logs\r\n",
        "\r\n",
        "train_step = AutoMLStep(name='AutoML_Classification',\r\n",
        "    automl_config=automl_config,\r\n",
        "    outputs=[metrics_data,model_data],\r\n",
        "    enable_default_model_output=False,\r\n",
        "    enable_default_metrics_output=False,)"
      ],
      "outputs": [],
      "execution_count": 122,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.core.graph import PipelineParameter\r\n",
        "\r\n",
        "# The model name with which to register the trained model in the workspace.\r\n",
        "model_name = PipelineParameter(\"model_name\", default_value=\"AutoML_Classification_Test\")\r\n",
        "\r\n",
        "register_step = PythonScriptStep(\r\n",
        "     name=\"register_model\",\r\n",
        "     script_name=\"register_model.py\",\r\n",
        "     source_directory=\"./Scripts\",\r\n",
        "     allow_reuse=False,\r\n",
        "     arguments=[\"--model_name\", model_name, \"--model_path\", model_data],\r\n",
        "     inputs=[model_data],\r\n",
        "     compute_target=compute_target,\r\n",
        "     runconfig=pipeline_run_config)"
      ],
      "outputs": [],
      "execution_count": 126,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.core import Pipeline\r\n",
        "from azureml.core import Experiment\r\n",
        "\r\n",
        "experiment = Experiment(ws, name= \"automl-classification-E2E_trainingPipeline\")\r\n",
        "\r\n",
        "pipeline = Pipeline(ws, [prep_step, train_step,register_step])\r\n",
        "\r\n",
        "run = experiment.submit(pipeline, show_output=True)\r\n",
        "run.wait_for_completion()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "kernel_info": {
      "name": "python38-azureml"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}